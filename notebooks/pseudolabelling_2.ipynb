{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('springboard_capstone_two': virtualenvwrapper)",
   "metadata": {
    "interpreter": {
     "hash": "1474d2ceccc6981c1385943cdbe44b9985a06ccaa858e7fff270717edcc51f5d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, average_precision_score, f1_score, roc_auc_score, plot_precision_recall_curve, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN \n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "import xgboost\n",
    "import lightgbm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.cm as cm \n",
    "import seaborn as sns \n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer, word_tokenize\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "import imblearn\n",
    "\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import flair \n",
    "\n",
    "from snorkel.labeling import labeling_function, PandasLFApplier, LFAnalysis, filter_unlabeled_dataframe\n",
    "from snorkel.analysis import get_label_buckets\n",
    "from snorkel.preprocess import preprocessor \n",
    "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
    "from snorkel.labeling.model import MajorityLabelVoter, LabelModel\n",
    "from snorkel.utils import probs_to_preds\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Steps we will perform in this exercise:\n",
    "\n",
    "1. Label a small number of samples (df_ground_truth)\n",
    "2. Use weak supervision (Generator) to label the unlabelled samples (df_unlabelled)\n",
    "3. Use a supervised model based on ground truth labels and weak supervised labels to classify the sentiment (Discriminator)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Weak supervision\n",
    "\n",
    "To generate pseudolabel, we have 4 common types of labeling functions:\n",
    "\n",
    "1. Hard-coded heuristics (in our problem, boycott tanishq is an obvious giveaway; however, (reject/don't support) boycott tanishq may be an indicaor of an opposite sentiment). We will try to label based on presence of this phrases in the tweet; otherwise we will abstain from labeling the tweet.\n",
    "2. Syntactics: Spacy's dependency trees can be a very good starting point for generating some more labels.\n",
    "3. Distant supervision: textblob, flair, vader sentiment analyzer.\n",
    "4. External models: other models that can generate some good labels."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/tanishq_data_clean_labelled.csv')\n",
    "df.drop(['Unnamed: 0', 'Unnamed: 0.1'], inplace=True, axis=1)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = TweetTokenizer()\n",
    "df['clean_tweet_token'] = df['clean_tweet_segmented'].apply(lemmatizer.lemmatize).apply(tokenizer.tokenize)\n",
    "df['clean_tweet_token'] = df['clean_tweet_token'].str.join(' ')\n",
    "df = df[['clean_tweet_token', 'sentiment']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ground_truth = df[df['sentiment'].isin([0.0, 4.0])]\n",
    "df_ground_truth['sentiment'] = df_ground_truth['sentiment'].replace({4.0: 1, 0.0: -1})\n",
    "df_ground_truth_generator, df_ground_truth_discriminator = train_test_split(df_ground_truth, test_size=0.25, stratify=df_ground_truth['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unlabelled = df[df['sentiment'].isin([np.nan, 10.0])]\n",
    "df_unlabelled.drop('sentiment', axis=1, inplace=True)\n",
    "del df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_colwidth', 0)\n",
    "#df_ground_truth[df_ground_truth['sentiment'] == -1.00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-02-18 16:16:32,511 loading file /Users/mamu867/.flair/models/sentiment-en-mix-distillbert_3.1.pt\n"
     ]
    }
   ],
   "source": [
    "# Labeling function\n",
    "\n",
    "# Textblob \n",
    "@preprocessor(memoize=True)\n",
    "def textblob_sentiment(x):\n",
    "    scores = TextBlob(x.clean_tweet_token)\n",
    "    x.tb_polarity = scores.sentiment.polarity\n",
    "    x.tb_subjectivity = scores.sentiment.subjectivity\n",
    "    return x \n",
    "\n",
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_polarity(x):\n",
    "    return 1 if x.tb_polarity > 0 else -1\n",
    "\n",
    "# Vader\n",
    "@preprocessor(memoize=True)\n",
    "def vader_sentiment(x):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(x.clean_tweet_token)\n",
    "    x.vd_polarity = scores['compound']\n",
    "    return x \n",
    "\n",
    "@labeling_function(pre=[vader_sentiment])\n",
    "def vader_polarity(x):\n",
    "    return 1 if x.vd_polarity > 0 else -1\n",
    "\n",
    "# Flair\n",
    "flair_sent = flair.models.TextClassifier.load('en-sentiment')\n",
    "@preprocessor(memoize=True)\n",
    "def flair_sentiment(x):\n",
    "    s = flair.data.Sentence(x.clean_tweet_token)\n",
    "    flair_sent.predict(s)\n",
    "    x.fl_polarity =  s.get_label_names()[0].lower()\n",
    "    return x \n",
    "\n",
    "@labeling_function(pre=[flair_sentiment])\n",
    "def flair_polarity(x):\n",
    "    return 1 if x.fl_polarity == 'positive' else -1\n",
    "\n",
    "# Positive sentiments about Tanishq\n",
    "search = r\"(support tanishq | ek at vam)\"\n",
    "\n",
    "@labeling_function()\n",
    "def positive_tanishq(x):\n",
    "    return 1 if re.search(search, x.clean_tweet_token, flags=re.I) else 0\n",
    "\n",
    "# Negative sentiments about Tanishq\n",
    "search = r\"(boycott tanishq | boycott bollywood | boycott amazon | hindu | offended | local | not respect | tradition | hindus | teach | losing | trust)\"\n",
    "\n",
    "@labeling_function()\n",
    "def negative_tanishq(x):\n",
    "    return -1 if re.search(search, x.clean_tweet_token, flags=re.I) else 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                      clean_tweet_token  sentiment\n",
       "652   kick out your ad film makers and directors or ...      -1.00\n",
       "1212  why always sanatan culture on target and get d...      -1.00\n",
       "598   time to boycott tanishq again boycott tanishq ...      -1.00\n",
       "2195  so this dhanteras stop buying jewellery frm ta...      -1.00\n",
       "1437  waiting for an ad by on bakr i d where the act...      -1.00\n",
       "...                                                 ...        ...\n",
       "2150  boycott tanishq you are losing all your trust ...      -1.00\n",
       "432   can you please stop this nonsense by one of yo...      -1.00\n",
       "1112  anti hindu tanishq marketing their products us...      -1.00\n",
       "266   you don t hold any responsibility sir for hurt...      -1.00\n",
       "416   boycott tanishq jewelry why only our festivals...      -1.00\n",
       "\n",
       "[275 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clean_tweet_token</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>652</th>\n      <td>kick out your ad film makers and directors or ...</td>\n      <td>-1.00</td>\n    </tr>\n    <tr>\n      <th>1212</th>\n      <td>why always sanatan culture on target and get d...</td>\n      <td>-1.00</td>\n    </tr>\n    <tr>\n      <th>598</th>\n      <td>time to boycott tanishq again boycott tanishq ...</td>\n      <td>-1.00</td>\n    </tr>\n    <tr>\n      <th>2195</th>\n      <td>so this dhanteras stop buying jewellery frm ta...</td>\n      <td>-1.00</td>\n    </tr>\n    <tr>\n      <th>1437</th>\n      <td>waiting for an ad by on bakr i d where the act...</td>\n      <td>-1.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2150</th>\n      <td>boycott tanishq you are losing all your trust ...</td>\n      <td>-1.00</td>\n    </tr>\n    <tr>\n      <th>432</th>\n      <td>can you please stop this nonsense by one of yo...</td>\n      <td>-1.00</td>\n    </tr>\n    <tr>\n      <th>1112</th>\n      <td>anti hindu tanishq marketing their products us...</td>\n      <td>-1.00</td>\n    </tr>\n    <tr>\n      <th>266</th>\n      <td>you don t hold any responsibility sir for hurt...</td>\n      <td>-1.00</td>\n    </tr>\n    <tr>\n      <th>416</th>\n      <td>boycott tanishq jewelry why only our festivals...</td>\n      <td>-1.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>275 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df_ground_truth_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "X_count_vec_gen = count_vec.fit_transform(df_ground_truth_generator['clean_tweet_token'])\n",
    "X_count_vec_dis = count_vec.transform(df_ground_truth_discriminator['clean_tweet_token'])\n",
    "y_gen = df_ground_truth_generator['sentiment'].values\n",
    "y_dis = df_ground_truth_discriminator['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "knn = KNN()\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "xgb = xgboost.XGBClassifier()\n",
    "lgb = lightgbm.LGBMClassifier(random_state=42)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "svc = SVC(probability=True, random_state=42)\n",
    "lin_svc = LinearSVC(random_state=42)\n",
    "\n",
    "classifiers = {'lr': lr, 'knn': knn, 'dt': dt,  'lda': lda, 'svc': svc, 'xgb': xgb, 'lgb': lgb, 'lin_svc': lin_svc}\n",
    "\n",
    "for clf in classifiers:\n",
    "    classifiers[clf].fit(X_count_vec_gen.toarray(), y_gen)\n",
    "\n",
    "@labeling_function()\n",
    "def lr_label(x):\n",
    "    return classifiers['lr'].predict(count_vec.transform(x).toarray())\n",
    "\n",
    "@labeling_function()\n",
    "def knn_label(x):\n",
    "    return classifiers['knn'].predict(count_vec.transform(x).toarray())\n",
    "\n",
    "@labeling_function()\n",
    "def dt_label(x):\n",
    "    return classifiers['dt'].predict(count_vec.transform(x).toarray())\n",
    "\n",
    "@labeling_function()\n",
    "def xgb_label(x):\n",
    "    return classifiers['xgb'].predict(count_vec.transform(x).toarray())\n",
    "\n",
    "@labeling_function()\n",
    "def lgb_label(x):\n",
    "    return classifiers['lgb'].predict(count_vec.transform(x).toarray())\n",
    "\n",
    "@labeling_function()\n",
    "def lda_label(x):\n",
    "    return classifiers['lda'].predict(count_vec.transform(x).toarray())\n",
    "\n",
    "@labeling_function()\n",
    "def svc_label(x):\n",
    "    return classifiers['svc'].predict(count_vec.transform(x).toarray())\n",
    "\n",
    "@labeling_function()\n",
    "def lin_svc_label(x):\n",
    "    return classifiers['lin_svc'].predict(count_vec.transform(x).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1500/1500 [01:11<00:00, 21.06it/s]\n"
     ]
    }
   ],
   "source": [
    "lfs = [textblob_polarity, vader_polarity, flair_polarity, positive_tanishq, negative_tanishq, lr_label, knn_label, dt_label, xgb_label, lgb_label, lda_label, svc_label, lin_svc_label]\n",
    "\n",
    "applier = PandasLFApplier(lfs)\n",
    "df_unlabelled = df_unlabelled.sample(1500, random_state=42)\n",
    "L_train = applier.apply(df_unlabelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    j Polarity  Coverage  Overlaps  Conflicts\n",
       "textblob_polarity   0      [1]      0.16      0.16       0.04\n",
       "vader_polarity      1      [1]      0.18      0.18       0.05\n",
       "flair_polarity      2      [1]      0.02      0.02       0.01\n",
       "positive_tanishq    3   [0, 1]      1.00      0.83       0.43\n",
       "negative_tanishq    4      [0]      0.48      0.48       0.43\n",
       "lr_label            5      [1]      0.00      0.00       0.00\n",
       "knn_label           6       []      0.00      0.00       0.00\n",
       "dt_label            7      [1]      0.01      0.01       0.01\n",
       "xgb_label           8      [1]      0.00      0.00       0.00\n",
       "lgb_label           9      [1]      0.01      0.01       0.00\n",
       "lda_label          10      [1]      0.59      0.59       0.38\n",
       "svc_label          11       []      0.00      0.00       0.00\n",
       "lin_svc_label      12      [1]      0.01      0.01       0.00"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>j</th>\n      <th>Polarity</th>\n      <th>Coverage</th>\n      <th>Overlaps</th>\n      <th>Conflicts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>textblob_polarity</th>\n      <td>0</td>\n      <td>[1]</td>\n      <td>0.16</td>\n      <td>0.16</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>vader_polarity</th>\n      <td>1</td>\n      <td>[1]</td>\n      <td>0.18</td>\n      <td>0.18</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>flair_polarity</th>\n      <td>2</td>\n      <td>[1]</td>\n      <td>0.02</td>\n      <td>0.02</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>positive_tanishq</th>\n      <td>3</td>\n      <td>[0, 1]</td>\n      <td>1.00</td>\n      <td>0.83</td>\n      <td>0.43</td>\n    </tr>\n    <tr>\n      <th>negative_tanishq</th>\n      <td>4</td>\n      <td>[0]</td>\n      <td>0.48</td>\n      <td>0.48</td>\n      <td>0.43</td>\n    </tr>\n    <tr>\n      <th>lr_label</th>\n      <td>5</td>\n      <td>[1]</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>knn_label</th>\n      <td>6</td>\n      <td>[]</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>dt_label</th>\n      <td>7</td>\n      <td>[1]</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>xgb_label</th>\n      <td>8</td>\n      <td>[1]</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>lgb_label</th>\n      <td>9</td>\n      <td>[1]</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>lda_label</th>\n      <td>10</td>\n      <td>[1]</td>\n      <td>0.59</td>\n      <td>0.59</td>\n      <td>0.38</td>\n    </tr>\n    <tr>\n      <th>svc_label</th>\n      <td>11</td>\n      <td>[]</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>lin_svc_label</th>\n      <td>12</td>\n      <td>[1]</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "LFAnalysis(L_train, lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_model = MajorityLabelVoter()\n",
    "preds_train = majority_model.predict(L=L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, lr=0.001, log_freq=100, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 275/275 [00:20<00:00, 13.13it/s]\n",
      "Majority Vote Accuracy:   100.0%\n",
      "Label Model Accuracy:     69.2%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L_test = applier.apply(df=df_ground_truth_generator[['clean_tweet_token']])\n",
    "\n",
    "majority_accuracy = majority_model.score(L=L_test, Y=df_ground_truth_generator['sentiment'], tie_break_policy=\"random\", metrics=['accuracy'])['accuracy']\n",
    "\n",
    "print(f\"\\n{'Majority Vote Accuracy:':<25} {majority_accuracy * 100:0.1f}%\")\n",
    "\n",
    "label_model_accuracy = label_model.score(L=L_test,Y=df_ground_truth_generator['sentiment'], tie_break_policy=\"random\", metrics=['accuracy'])['accuracy']\n",
    "\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_accuracy * 100:0.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                      clean_tweet_token\n",
       "4833  from next year every hindu shud advice those p...\n",
       "5516  do not waste you energy on anti hindus anti hi...\n",
       "1755  celebrate diwali with this great bomb and give...\n",
       "2726  the most popular hobbies around the world we w...\n",
       "3805                      so true let s boycott tanishq\n",
       "4969  tanishq is brand of tata co amp i really respe...\n",
       "8011  enjoy diwali with crackers it s hindu indian f...\n",
       "6619  hindus please burst as many crackers as possib...\n",
       "2173  there is no crackers ban in haryana hours up m...\n",
       "7082  hey tanishq pr team yesterday we did gold shop..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clean_tweet_token</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4833</th>\n      <td>from next year every hindu shud advice those p...</td>\n    </tr>\n    <tr>\n      <th>5516</th>\n      <td>do not waste you energy on anti hindus anti hi...</td>\n    </tr>\n    <tr>\n      <th>1755</th>\n      <td>celebrate diwali with this great bomb and give...</td>\n    </tr>\n    <tr>\n      <th>2726</th>\n      <td>the most popular hobbies around the world we w...</td>\n    </tr>\n    <tr>\n      <th>3805</th>\n      <td>so true let s boycott tanishq</td>\n    </tr>\n    <tr>\n      <th>4969</th>\n      <td>tanishq is brand of tata co amp i really respe...</td>\n    </tr>\n    <tr>\n      <th>8011</th>\n      <td>enjoy diwali with crackers it s hindu indian f...</td>\n    </tr>\n    <tr>\n      <th>6619</th>\n      <td>hindus please burst as many crackers as possib...</td>\n    </tr>\n    <tr>\n      <th>2173</th>\n      <td>there is no crackers ban in haryana hours up m...</td>\n    </tr>\n    <tr>\n      <th>7082</th>\n      <td>hey tanishq pr team yesterday we did gold shop...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "buckets = get_label_buckets(L_train[:, 0], L_train[:, 1], L_train[:, 2])\n",
    "df_unlabelled.iloc[buckets[(1, 1, 1)]].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n        -1.0       1.00      0.02      0.04       262\n         0.0       0.00      0.00      0.00         0\n         1.0       0.05      1.00      0.10        13\n\n    accuracy                           0.07       275\n   macro avg       0.35      0.34      0.05       275\nweighted avg       0.96      0.07      0.04       275\n\n"
     ]
    }
   ],
   "source": [
    "y_ground_truth_pred = majority_model.predict(L_test)\n",
    "print(classification_report(df_ground_truth_generator['sentiment'].values, y_ground_truth_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlabelled = count_vec.transform(df_unlabelled['clean_tweet_token']).toarray()[preds_train != 0]\n",
    "y_unlabelled = preds_train[preds_train != 0]\n",
    "y_unlabelled[y_unlabelled == -1] = 0\n",
    "X_train = np.concatenate([X_count_vec_gen.toarray(), X_unlabelled])\n",
    "y_train = np.concatenate([y_gen, y_unlabelled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30/30 [00:52<00:00,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "clf_cv = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models_cv, predictions_cv = clf_cv.fit(X_train, X_count_vec_dis.toarray(), y_train, y_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "GaussianNB                         0.34               0.65     0.66      0.44   \n",
       "SVC                                0.22               0.59     0.59      0.28   \n",
       "DecisionTreeClassifier             0.39               0.58     0.59      0.51   \n",
       "RandomForestClassifier             0.20               0.57     0.57      0.25   \n",
       "BernoulliNB                        0.35               0.56     0.56      0.46   \n",
       "SGDClassifier                      0.32               0.54     0.57      0.43   \n",
       "CalibratedClassifierCV             0.10               0.52     0.52      0.09   \n",
       "CheckingClassifier                 0.95               0.50     0.50      0.92   \n",
       "ExtraTreesClassifier               0.23               0.50     0.52      0.31   \n",
       "NearestCentroid                    0.39               0.49     0.56      0.52   \n",
       "LGBMClassifier                     0.33               0.46     0.47      0.45   \n",
       "XGBClassifier                      0.33               0.46     0.49      0.45   \n",
       "AdaBoostClassifier                 0.26               0.42     0.42      0.37   \n",
       "KNeighborsClassifier               0.08               0.42     0.44      0.07   \n",
       "DummyClassifier                    0.25               0.41     0.46      0.35   \n",
       "PassiveAggressiveClassifier        0.42               0.41     0.53      0.56   \n",
       "Perceptron                         0.38               0.39     0.44      0.52   \n",
       "BaggingClassifier                  0.34               0.37     0.40      0.47   \n",
       "RidgeClassifierCV                  0.33               0.36     0.42      0.46   \n",
       "ExtraTreeClassifier                0.30               0.35     0.35      0.43   \n",
       "QuadraticDiscriminantAnalysis      0.63               0.33     0.42      0.74   \n",
       "LinearDiscriminantAnalysis         0.38               0.30     0.50      0.53   \n",
       "RidgeClassifier                    0.35               0.28     0.39      0.49   \n",
       "LinearSVC                          0.32               0.26     0.39      0.46   \n",
       "LabelSpreading                     0.00               0.00     0.41      0.00   \n",
       "LabelPropagation                   0.00               0.00     0.50      0.00   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "GaussianNB                           0.13  \n",
       "SVC                                  2.15  \n",
       "DecisionTreeClassifier               0.18  \n",
       "RandomForestClassifier               0.63  \n",
       "BernoulliNB                          0.09  \n",
       "SGDClassifier                        0.40  \n",
       "CalibratedClassifierCV              30.38  \n",
       "CheckingClassifier                   0.08  \n",
       "ExtraTreesClassifier                 0.99  \n",
       "NearestCentroid                      0.10  \n",
       "LGBMClassifier                       0.69  \n",
       "XGBClassifier                        3.79  \n",
       "AdaBoostClassifier                   0.73  \n",
       "KNeighborsClassifier                 0.37  \n",
       "DummyClassifier                      0.09  \n",
       "PassiveAggressiveClassifier          0.40  \n",
       "Perceptron                           0.18  \n",
       "BaggingClassifier                    0.70  \n",
       "RidgeClassifierCV                    0.35  \n",
       "ExtraTreeClassifier                  0.10  \n",
       "QuadraticDiscriminantAnalysis        0.36  \n",
       "LinearDiscriminantAnalysis           0.66  \n",
       "RidgeClassifier                      0.16  \n",
       "LinearSVC                            7.41  \n",
       "LabelSpreading                       0.12  \n",
       "LabelPropagation                     0.78  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Balanced Accuracy</th>\n      <th>ROC AUC</th>\n      <th>F1 Score</th>\n      <th>Time Taken</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>GaussianNB</th>\n      <td>0.34</td>\n      <td>0.65</td>\n      <td>0.66</td>\n      <td>0.44</td>\n      <td>0.13</td>\n    </tr>\n    <tr>\n      <th>SVC</th>\n      <td>0.22</td>\n      <td>0.59</td>\n      <td>0.59</td>\n      <td>0.28</td>\n      <td>2.15</td>\n    </tr>\n    <tr>\n      <th>DecisionTreeClassifier</th>\n      <td>0.39</td>\n      <td>0.58</td>\n      <td>0.59</td>\n      <td>0.51</td>\n      <td>0.18</td>\n    </tr>\n    <tr>\n      <th>RandomForestClassifier</th>\n      <td>0.20</td>\n      <td>0.57</td>\n      <td>0.57</td>\n      <td>0.25</td>\n      <td>0.63</td>\n    </tr>\n    <tr>\n      <th>BernoulliNB</th>\n      <td>0.35</td>\n      <td>0.56</td>\n      <td>0.56</td>\n      <td>0.46</td>\n      <td>0.09</td>\n    </tr>\n    <tr>\n      <th>SGDClassifier</th>\n      <td>0.32</td>\n      <td>0.54</td>\n      <td>0.57</td>\n      <td>0.43</td>\n      <td>0.40</td>\n    </tr>\n    <tr>\n      <th>CalibratedClassifierCV</th>\n      <td>0.10</td>\n      <td>0.52</td>\n      <td>0.52</td>\n      <td>0.09</td>\n      <td>30.38</td>\n    </tr>\n    <tr>\n      <th>CheckingClassifier</th>\n      <td>0.95</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.92</td>\n      <td>0.08</td>\n    </tr>\n    <tr>\n      <th>ExtraTreesClassifier</th>\n      <td>0.23</td>\n      <td>0.50</td>\n      <td>0.52</td>\n      <td>0.31</td>\n      <td>0.99</td>\n    </tr>\n    <tr>\n      <th>NearestCentroid</th>\n      <td>0.39</td>\n      <td>0.49</td>\n      <td>0.56</td>\n      <td>0.52</td>\n      <td>0.10</td>\n    </tr>\n    <tr>\n      <th>LGBMClassifier</th>\n      <td>0.33</td>\n      <td>0.46</td>\n      <td>0.47</td>\n      <td>0.45</td>\n      <td>0.69</td>\n    </tr>\n    <tr>\n      <th>XGBClassifier</th>\n      <td>0.33</td>\n      <td>0.46</td>\n      <td>0.49</td>\n      <td>0.45</td>\n      <td>3.79</td>\n    </tr>\n    <tr>\n      <th>AdaBoostClassifier</th>\n      <td>0.26</td>\n      <td>0.42</td>\n      <td>0.42</td>\n      <td>0.37</td>\n      <td>0.73</td>\n    </tr>\n    <tr>\n      <th>KNeighborsClassifier</th>\n      <td>0.08</td>\n      <td>0.42</td>\n      <td>0.44</td>\n      <td>0.07</td>\n      <td>0.37</td>\n    </tr>\n    <tr>\n      <th>DummyClassifier</th>\n      <td>0.25</td>\n      <td>0.41</td>\n      <td>0.46</td>\n      <td>0.35</td>\n      <td>0.09</td>\n    </tr>\n    <tr>\n      <th>PassiveAggressiveClassifier</th>\n      <td>0.42</td>\n      <td>0.41</td>\n      <td>0.53</td>\n      <td>0.56</td>\n      <td>0.40</td>\n    </tr>\n    <tr>\n      <th>Perceptron</th>\n      <td>0.38</td>\n      <td>0.39</td>\n      <td>0.44</td>\n      <td>0.52</td>\n      <td>0.18</td>\n    </tr>\n    <tr>\n      <th>BaggingClassifier</th>\n      <td>0.34</td>\n      <td>0.37</td>\n      <td>0.40</td>\n      <td>0.47</td>\n      <td>0.70</td>\n    </tr>\n    <tr>\n      <th>RidgeClassifierCV</th>\n      <td>0.33</td>\n      <td>0.36</td>\n      <td>0.42</td>\n      <td>0.46</td>\n      <td>0.35</td>\n    </tr>\n    <tr>\n      <th>ExtraTreeClassifier</th>\n      <td>0.30</td>\n      <td>0.35</td>\n      <td>0.35</td>\n      <td>0.43</td>\n      <td>0.10</td>\n    </tr>\n    <tr>\n      <th>QuadraticDiscriminantAnalysis</th>\n      <td>0.63</td>\n      <td>0.33</td>\n      <td>0.42</td>\n      <td>0.74</td>\n      <td>0.36</td>\n    </tr>\n    <tr>\n      <th>LinearDiscriminantAnalysis</th>\n      <td>0.38</td>\n      <td>0.30</td>\n      <td>0.50</td>\n      <td>0.53</td>\n      <td>0.66</td>\n    </tr>\n    <tr>\n      <th>RidgeClassifier</th>\n      <td>0.35</td>\n      <td>0.28</td>\n      <td>0.39</td>\n      <td>0.49</td>\n      <td>0.16</td>\n    </tr>\n    <tr>\n      <th>LinearSVC</th>\n      <td>0.32</td>\n      <td>0.26</td>\n      <td>0.39</td>\n      <td>0.46</td>\n      <td>7.41</td>\n    </tr>\n    <tr>\n      <th>LabelSpreading</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.41</td>\n      <td>0.00</td>\n      <td>0.12</td>\n    </tr>\n    <tr>\n      <th>LabelPropagation</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.78</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "models_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}